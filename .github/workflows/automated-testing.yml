name: Automated Testing Suite

on:
  push:
    branches: [ main, develop ]
    # Note: initialbuild branch testing handled by deploy-webapp.yml
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run automated tests every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - performance
          - security
          - react-hooks

jobs:
  # Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.test_suite == 'unit' || github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: webapp/frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd webapp/frontend
        npm ci
        
    - name: Run unit tests
      run: |
        cd webapp/frontend
        npm run test:unit
        
    - name: Generate coverage report
      run: |
        cd webapp/frontend
        npm run test:coverage
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./webapp/frontend/coverage/lcov.info
        flags: unittests
        name: codecov-umbrella
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results
        path: |
          webapp/frontend/test-results/
          webapp/frontend/coverage/
          
    - name: Configure AWS credentials
      if: always()
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsTestResultsRole
        aws-region: us-east-1
        
    - name: Upload test results to S3
      if: always()
      continue-on-error: true
      run: |
        cd webapp/frontend
        
        # Install jq if not available
        if ! command -v jq &> /dev/null; then
          sudo apt-get update && sudo apt-get install -y jq
        fi
        
        # Create timestamped directory for this test run
        TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
        RUN_ID="${{ github.run_id }}"
        BRANCH_NAME="${GITHUB_REF#refs/heads/}"
        
        echo "📊 Preparing test results for upload..."
        echo "Timestamp: ${TIMESTAMP}"
        echo "Run ID: ${RUN_ID}"
        echo "Branch: ${BRANCH_NAME}"
        
        # Create local directory structure
        mkdir -p "test-upload/unit-tests-${TIMESTAMP}"
        
        # Always copy test-results directory even if tests failed
        if [ -d "test-results" ]; then
          cp -r test-results/* "test-upload/unit-tests-${TIMESTAMP}/"
          echo "✅ Copied test-results directory"
        else
          echo "⚠️ No test-results directory found"
          echo "No test results available" > "test-upload/unit-tests-${TIMESTAMP}/NO_RESULTS.txt"
        fi
        
        # Copy coverage if it exists
        if [ -d "coverage" ]; then
          mkdir -p "test-upload/coverage-${TIMESTAMP}"
          cp -r coverage/* "test-upload/coverage-${TIMESTAMP}/"
          echo "✅ Copied coverage directory"
        fi
        
        # Create comprehensive summary file
        SUMMARY_FILE="test-upload/unit-tests-${TIMESTAMP}/SUMMARY.md"
        echo "# Unit Test Results - ${TIMESTAMP}" > "${SUMMARY_FILE}"
        echo "" >> "${SUMMARY_FILE}"
        echo "**Test Run:** $(date)" >> "${SUMMARY_FILE}"
        echo "**Branch:** ${BRANCH_NAME}" >> "${SUMMARY_FILE}"
        echo "**Commit:** ${GITHUB_SHA}" >> "${SUMMARY_FILE}"
        echo "**Workflow Run:** ${RUN_ID}" >> "${SUMMARY_FILE}"
        echo "**GitHub Actor:** ${{ github.actor }}" >> "${SUMMARY_FILE}"
        echo "" >> "${SUMMARY_FILE}"
        
        # Try to extract detailed metrics from results.json
        RESULTS_FILE="test-results/results.json"
        if [ -f "${RESULTS_FILE}" ]; then
          echo "## Test Summary" >> "${SUMMARY_FILE}"
          echo "" >> "${SUMMARY_FILE}"
          
          if command -v jq &> /dev/null; then
            TOTAL_TESTS=$(jq -r '.numTotalTests // "N/A"' "${RESULTS_FILE}" 2>/dev/null || echo "N/A")
            PASSED_TESTS=$(jq -r '.numPassedTests // "N/A"' "${RESULTS_FILE}" 2>/dev/null || echo "N/A")
            FAILED_TESTS=$(jq -r '.numFailedTests // "N/A"' "${RESULTS_FILE}" 2>/dev/null || echo "N/A")
            PENDING_TESTS=$(jq -r '.numPendingTests // "N/A"' "${RESULTS_FILE}" 2>/dev/null || echo "N/A")
            SUCCESS=$(jq -r '.success // false' "${RESULTS_FILE}" 2>/dev/null || echo "false")
            
            echo "- **Total Tests:** ${TOTAL_TESTS}" >> "${SUMMARY_FILE}"
            echo "- **Passed:** ${PASSED_TESTS}" >> "${SUMMARY_FILE}"
            echo "- **Failed:** ${FAILED_TESTS}" >> "${SUMMARY_FILE}"
            echo "- **Pending:** ${PENDING_TESTS}" >> "${SUMMARY_FILE}"
            echo "- **Success:** ${SUCCESS}" >> "${SUMMARY_FILE}"
            echo "" >> "${SUMMARY_FILE}"
            
            # Extract failed test details if any
            if [ "${FAILED_TESTS}" != "0" ] && [ "${FAILED_TESTS}" != "N/A" ]; then
              echo "## Failed Tests" >> "${SUMMARY_FILE}"
              echo "" >> "${SUMMARY_FILE}"
              jq -r '.testResults[] | select(.status == "failed") | "- " + .name' "${RESULTS_FILE}" >> "${SUMMARY_FILE}" 2>/dev/null || echo "Failed test details not available" >> "${SUMMARY_FILE}"
              echo "" >> "${SUMMARY_FILE}"
            fi
          else
            echo "- **Status:** Unable to parse results (jq not available)" >> "${SUMMARY_FILE}"
          fi
          
          echo "**Raw Results:** Available in \`results.json\`" >> "${SUMMARY_FILE}"
        else
          echo "## Test Status" >> "${SUMMARY_FILE}"
          echo "" >> "${SUMMARY_FILE}"
          echo "⚠️ **No results.json found** - tests may have failed to complete" >> "${SUMMARY_FILE}"
          echo "" >> "${SUMMARY_FILE}"
          
          echo "**Available files:**" >> "${SUMMARY_FILE}"
          echo "\`\`\`" >> "${SUMMARY_FILE}"
          ls -la test-results/ >> "${SUMMARY_FILE}" 2>/dev/null || echo "No test-results directory found" >> "${SUMMARY_FILE}"
          echo "\`\`\`" >> "${SUMMARY_FILE}"
        fi
        
        echo "" >> "${SUMMARY_FILE}"
        echo "---" >> "${SUMMARY_FILE}"
        echo "**S3 Location:** \`s3://algo-test-results/unit-tests/${BRANCH_NAME}/unit-tests-${TIMESTAMP}/\`" >> "${SUMMARY_FILE}"
        echo "**Accessible via:** Claude Code can read these results directly from S3" >> "${SUMMARY_FILE}"
        
        # Create a latest.json pointer file
        echo "{\"timestamp\":\"${TIMESTAMP}\",\"runId\":\"${RUN_ID}\",\"branch\":\"${BRANCH_NAME}\",\"commit\":\"${GITHUB_SHA}\",\"path\":\"unit-tests/${BRANCH_NAME}/unit-tests-${TIMESTAMP}/\"}" > "test-upload/latest-run.json"
        
        # Get the actual bucket name from CloudFormation stack
        STACK_NAME="stocks-webapp-dev"
        AWS_ACCOUNT_ID="${{ secrets.AWS_ACCOUNT_ID }}"
        
        echo "🔍 Checking CloudFormation stack: ${STACK_NAME}"
        echo "🆔 AWS Account ID: ${AWS_ACCOUNT_ID}"
        
        # Try to get bucket name from CloudFormation stack first
        BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name ${STACK_NAME} --query 'Stacks[0].Outputs[?OutputKey==`TestResultsBucketName`].OutputValue' --output text 2>/dev/null)
        
        # If CloudFormation query fails, construct bucket name based on naming pattern
        if [ -z "$BUCKET_NAME" ] || [ "$BUCKET_NAME" = "None" ]; then
          BUCKET_NAME="algo-test-results-dev-${AWS_ACCOUNT_ID}"
          echo "⚠️ CloudFormation stack query failed, using constructed bucket name: ${BUCKET_NAME}"
        else
          echo "✅ Found bucket name from CloudFormation: ${BUCKET_NAME}"
        fi
        
        echo "📤 Uploading test results to S3 bucket: ${BUCKET_NAME}"
        
        # Verify AWS credentials are working
        echo "🔐 Testing AWS credentials..."
        aws sts get-caller-identity || (echo "❌ AWS credentials not working" && exit 1)
        
        # Check if bucket exists and is accessible
        echo "🪣 Checking bucket accessibility..."
        if aws s3 ls "s3://${BUCKET_NAME}/" >/dev/null 2>&1; then
          echo "✅ Bucket is accessible"
        else
          echo "❌ Bucket is not accessible or does not exist"
          echo "📝 Attempting to list available buckets..."
          aws s3 ls
          exit 1
        fi
        
        # Show what we're about to upload
        echo "📂 Files to upload:"
        find test-upload/ -type f | head -20
        
        # Upload the test results with error handling
        echo "📤 Uploading test results directory..."
        if aws s3 cp "test-upload/" "s3://${BUCKET_NAME}/unit-tests/${BRANCH_NAME}/" --recursive --acl public-read; then
          echo "✅ Test results uploaded successfully"
        else
          echo "❌ Failed to upload test results"
          exit 1
        fi
        
        # Upload latest pointer
        echo "📤 Uploading latest run pointer..."
        if aws s3 cp "test-upload/latest-run.json" "s3://${BUCKET_NAME}/latest-unit-test-run.json" --acl public-read; then
          echo "✅ Latest run pointer uploaded"
        else
          echo "❌ Failed to upload latest run pointer"
          exit 1
        fi
        
        # Also create a branch-specific latest pointer
        echo "📤 Uploading branch-specific pointer..."
        if aws s3 cp "test-upload/latest-run.json" "s3://${BUCKET_NAME}/latest-unit-test-run-${BRANCH_NAME}.json" --acl public-read; then
          echo "✅ Branch-specific pointer uploaded"
        else
          echo "❌ Failed to upload branch-specific pointer"
          exit 1
        fi
        
        echo "✅ Test results uploaded successfully!"
        echo "📋 Summary available at: https://${BUCKET_NAME}.s3.amazonaws.com/unit-tests/${BRANCH_NAME}/unit-tests-${TIMESTAMP}/SUMMARY.md"
        echo "📊 Results available at: https://${BUCKET_NAME}.s3.amazonaws.com/unit-tests/${BRANCH_NAME}/unit-tests-${TIMESTAMP}/results.json"
        echo "🔗 Latest run info: https://${BUCKET_NAME}.s3.amazonaws.com/latest-unit-test-run.json"
          
  # Integration Tests - DISABLED: Now handled by deploy-webapp.yml
  integration-tests:
    name: Integration Tests (Disabled - Use deploy-webapp workflow)
    runs-on: ubuntu-latest
    if: false  # Disabled - integration tests now run in deploy-webapp.yml
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: webapp/frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd webapp/frontend
        npm ci
        
    - name: Setup test database
      run: |
        cd webapp/lambda
        npm install
        POSTGRES_HOST=localhost POSTGRES_PORT=5432 POSTGRES_DB=testdb POSTGRES_USER=testuser POSTGRES_PASSWORD=testpass node test-db-setup.js
        
    - name: Run integration tests
      run: |
        cd webapp/frontend
        npm run test:integration
      env:
        API_BASE_URL: http://localhost:3000
        TEST_DATABASE_URL: postgres://testuser:testpass@localhost:5432/testdb
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: webapp/frontend/test-results/
        
  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.test_suite == 'performance' || github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: webapp/frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd webapp/frontend
        npm ci
        
    - name: Build application
      run: |
        cd webapp/frontend
        npm run build
        
    - name: Install Artillery
      run: npm install -g artillery@latest
      
    - name: Run performance tests
      run: |
        cd webapp/frontend
        npm run test:performance
        
    - name: Run load tests
      run: |
        cd webapp/frontend
        artillery run src/tests/performance/load-test.yml --output load-test-results.json
        
    - name: Generate performance report
      run: |
        cd webapp/frontend
        artillery report load-test-results.json --output performance-report.html
        
    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-test-results
        path: |
          webapp/frontend/load-test-results.json
          webapp/frontend/performance-report.html
          
  # Security Tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.test_suite == 'security' || github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: webapp/frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd webapp/frontend
        npm ci
        
    - name: Run security audit
      run: |
        cd webapp/frontend
        npm audit --audit-level=moderate
        
    - name: Run security tests
      run: |
        cd webapp/frontend
        npm run test:security
        
    - name: Install OWASP ZAP
      run: |
        sudo apt-get update
        sudo apt-get install -y wget
        wget https://github.com/zaproxy/zaproxy/releases/download/v2.14.0/ZAP_2.14.0_Linux.tar.gz
        tar -xzf ZAP_2.14.0_Linux.tar.gz
        
    - name: Build and start application
      run: |
        cd webapp/frontend
        npm run build
        npm run preview &
        sleep 30
        
    - name: Run OWASP ZAP security scan
      run: |
        cd ZAP_2.14.0
        ./zap.sh -cmd -quickurl http://localhost:4173 -quickprogress -quickout zap-report.html
        
    - name: Upload security results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-test-results
        path: |
          webapp/frontend/test-results/
          ZAP_2.14.0/zap-report.html
          
  # React Hooks Tests
  react-hooks-tests:
    name: React Hooks Tests
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.test_suite == 'react-hooks' || github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: webapp/frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd webapp/frontend
        npm ci
        
    - name: Run React hooks diagnostics
      run: |
        cd webapp/frontend
        npm run debug:react
        
    - name: Run React hooks tests
      run: |
        cd webapp/frontend
        npm run test:unit -- --testNamePattern="React Hooks"
        
    - name: Generate hooks diagnostic report
      run: |
        cd webapp/frontend
        node -e "
          const { runReactHooksDiagnostics } = require('./src/utils/reactHooksDebugger.js');
          runReactHooksDiagnostics().then(report => {
            console.log('React Hooks Diagnostic Report:', JSON.stringify(report, null, 2));
          });
        "
        
    - name: Upload hooks test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: react-hooks-test-results
        path: webapp/frontend/test-results/
        
  # E2E Tests with Playwright
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == '' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: webapp/frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd webapp/frontend
        npm ci
        
    - name: Install Playwright
      run: |
        cd webapp/frontend
        npx playwright install --with-deps chromium
        
    - name: Build application
      run: |
        cd webapp/frontend
        npm run build
        
    - name: Start application
      run: |
        cd webapp/frontend
        npm run preview &
        sleep 30
        
    - name: Run E2E tests
      run: |
        cd webapp/frontend
        npm run test:e2e
        
    - name: Upload E2E test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results
        path: |
          webapp/frontend/test-results/
          webapp/frontend/playwright-report/
          
  # Comprehensive Test Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, security-tests, react-hooks-tests, e2e-tests]
    if: always()
    
    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v4
      
    - name: Generate comprehensive test report
      run: |
        echo "# Comprehensive Test Report" > test-summary.md
        echo "" >> test-summary.md
        echo "## Test Results Overview" >> test-summary.md
        echo "" >> test-summary.md
        
        # Unit Tests
        if [ -d "unit-test-results" ]; then
          echo "✅ Unit Tests: Completed" >> test-summary.md
        else
          echo "❌ Unit Tests: Failed or Skipped" >> test-summary.md
        fi
        
        # Integration Tests
        if [ -d "integration-test-results" ]; then
          echo "✅ Integration Tests: Completed" >> test-summary.md
        else
          echo "❌ Integration Tests: Failed or Skipped" >> test-summary.md
        fi
        
        # Performance Tests
        if [ -d "performance-test-results" ]; then
          echo "✅ Performance Tests: Completed" >> test-summary.md
        else
          echo "❌ Performance Tests: Failed or Skipped" >> test-summary.md
        fi
        
        # Security Tests
        if [ -d "security-test-results" ]; then
          echo "✅ Security Tests: Completed" >> test-summary.md
        else
          echo "❌ Security Tests: Failed or Skipped" >> test-summary.md
        fi
        
        # React Hooks Tests
        if [ -d "react-hooks-test-results" ]; then
          echo "✅ React Hooks Tests: Completed" >> test-summary.md
        else
          echo "❌ React Hooks Tests: Failed or Skipped" >> test-summary.md
        fi
        
        # E2E Tests
        if [ -d "e2e-test-results" ]; then
          echo "✅ E2E Tests: Completed" >> test-summary.md
        else
          echo "❌ E2E Tests: Failed or Skipped" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "## Test Artifacts" >> test-summary.md
        echo "" >> test-summary.md
        echo "- Unit Test Results: $(ls -la unit-test-results/ 2>/dev/null | wc -l) files" >> test-summary.md
        echo "- Integration Test Results: $(ls -la integration-test-results/ 2>/dev/null | wc -l) files" >> test-summary.md
        echo "- Performance Test Results: $(ls -la performance-test-results/ 2>/dev/null | wc -l) files" >> test-summary.md
        echo "- Security Test Results: $(ls -la security-test-results/ 2>/dev/null | wc -l) files" >> test-summary.md
        echo "- React Hooks Test Results: $(ls -la react-hooks-test-results/ 2>/dev/null | wc -l) files" >> test-summary.md
        echo "- E2E Test Results: $(ls -la e2e-test-results/ 2>/dev/null | wc -l) files" >> test-summary.md
        
        cat test-summary.md
        
    - name: Upload test summary
      uses: actions/upload-artifact@v4
      with:
        name: test-summary
        path: test-summary.md
        
    - name: Comment PR with test results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('test-summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });
          
  # Quality Gates
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, security-tests]
    if: always()
    
    steps:
    - name: Evaluate quality gates
      run: |
        echo "Evaluating quality gates..."
        
        # Check if critical tests passed
        if [ "${{ needs.unit-tests.result }}" != "success" ]; then
          echo "❌ Unit tests failed - blocking deployment"
          exit 1
        fi
        
        if [ "${{ needs.integration-tests.result }}" != "success" ]; then
          echo "❌ Integration tests failed - blocking deployment"
          exit 1
        fi
        
        if [ "${{ needs.security-tests.result }}" != "success" ]; then
          echo "❌ Security tests failed - blocking deployment"
          exit 1
        fi
        
        # Performance tests are warning-only
        if [ "${{ needs.performance-tests.result }}" != "success" ]; then
          echo "⚠️ Performance tests failed - deployment allowed but needs attention"
        fi
        
        echo "✅ All quality gates passed"
        
    - name: Update deployment status
      if: success()
      run: |
        echo "✅ Quality gates passed - deployment approved"
        echo "DEPLOYMENT_APPROVED=true" >> $GITHUB_ENV
        
    - name: Block deployment on quality gate failure
      if: failure()
      run: |
        echo "❌ Quality gates failed - deployment blocked"
        echo "DEPLOYMENT_APPROVED=false" >> $GITHUB_ENV
        exit 1