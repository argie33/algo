name: Deploy Data Loaders

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'load*.py'
      - 'data_loader_orchestrator.py'
      - 'deploy_data_loaders.py'
      - 'Dockerfile.dataloader'
      - 'requirements.txt'
      - '.github/workflows/deploy-data-loaders.yml'
  
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      loaders:
        description: 'Comma-separated list of loaders to deploy (leave empty for all)'
        required: false
        default: ''
      run_immediately:
        description: 'Run loaders immediately after deployment'
        required: false
        default: 'true'
        type: boolean
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - staging
        - prod

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: financial-platform-data-loaders
  ECS_CLUSTER: financial-platform-cluster

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      changed-loaders: ${{ steps.changes.outputs.loaders }}
      deploy-all: ${{ steps.changes.outputs.deploy-all }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 2

      - name: Detect changed loaders
        id: changes
        run: |
          # Get list of changed Python loader files
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD | grep '^load.*\.py$' || true)
          
          if [[ -n "$CHANGED_FILES" ]]; then
            # Extract loader names (remove 'load' prefix and '.py' suffix)
            LOADERS=$(echo "$CHANGED_FILES" | sed 's/^load//' | sed 's/\.py$//' | tr '\n' ',' | sed 's/,$//')
            echo "loaders=$LOADERS" >> $GITHUB_OUTPUT
            echo "deploy-all=false" >> $GITHUB_OUTPUT
            echo "Changed loaders: $LOADERS"
          else
            # Check if core deployment files changed
            CORE_CHANGED=$(git diff --name-only HEAD^ HEAD | grep -E '(data_loader_orchestrator|deploy_data_loaders|Dockerfile|requirements)' || true)
            if [[ -n "$CORE_CHANGED" ]] || [[ "${{ github.event.inputs.loaders }}" == "" ]]; then
              echo "loaders=all" >> $GITHUB_OUTPUT
              echo "deploy-all=true" >> $GITHUB_OUTPUT
              echo "Core files changed or manual trigger - deploying all loaders"
            else
              echo "loaders=" >> $GITHUB_OUTPUT
              echo "deploy-all=false" >> $GITHUB_OUTPUT
              echo "No relevant changes detected"
            fi
          fi

  validate-environment:
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.changed-loaders != ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install boto3 psycopg2-binary yfinance pandas numpy

      - name: Validate loader scripts
        run: |
          python3 -c "
          import os
          import sys
          
          # Get loaders to validate
          loaders = '${{ needs.detect-changes.outputs.changed-loaders }}'
          if loaders == 'all':
              loader_files = [f for f in os.listdir('.') if f.startswith('load') and f.endswith('.py')]
          else:
              loader_files = [f'load{loader}.py' for loader in loaders.split(',') if loader]
          
          print(f'Validating {len(loader_files)} loader scripts...')
          
          errors = []
          for loader_file in loader_files:
              if not os.path.exists(loader_file):
                  errors.append(f'File not found: {loader_file}')
                  continue
              
              # Check if file is not empty
              if os.path.getsize(loader_file) == 0:
                  errors.append(f'File is empty: {loader_file}')
                  continue
              
              # Try to compile the Python file
              try:
                  with open(loader_file, 'r') as f:
                      compile(f.read(), loader_file, 'exec')
                  print(f'✅ {loader_file}')
              except SyntaxError as e:
                  errors.append(f'Syntax error in {loader_file}: {e}')
                  print(f'❌ {loader_file}: {e}')
          
          if errors:
              print(f'\\n❌ Validation failed with {len(errors)} errors:')
              for error in errors:
                  print(f'  - {error}')
              sys.exit(1)
          else:
              print(f'\\n✅ All {len(loader_files)} loader scripts validated successfully')
          "

  deploy-loaders:
    runs-on: ubuntu-latest
    needs: [detect-changes, validate-environment]
    if: needs.detect-changes.outputs.changed-loaders != ''
    environment: ${{ github.event.inputs.environment || 'dev' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install deployment dependencies
        run: |
          pip install boto3 docker

      - name: Create ECR repository if not exists
        run: |
          aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} || \
          aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}

      - name: Deploy data loaders
        id: deploy
        run: |
          # Determine which loaders to deploy
          if [[ "${{ github.event.inputs.loaders }}" != "" ]]; then
            LOADERS="${{ github.event.inputs.loaders }}"
          elif [[ "${{ needs.detect-changes.outputs.changed-loaders }}" == "all" ]]; then
            # Get all loader files
            LOADERS=$(ls load*.py | sed 's/^load//' | sed 's/\.py$//' | tr '\n' ',' | sed 's/,$//')
          else
            LOADERS="${{ needs.detect-changes.outputs.changed-loaders }}"
          fi
          
          echo "Deploying loaders: $LOADERS"
          echo "loaders=$LOADERS" >> $GITHUB_OUTPUT
          
          # Run deployment script
          python3 deploy_data_loaders.py ${LOADERS//,/ } --region ${{ env.AWS_REGION }}

      - name: Run data loaders
        if: github.event.inputs.run_immediately != 'false'
        run: |
          echo "Running deployed data loaders..."
          
          # Run the orchestrator with deployed loaders
          LOADERS="${{ steps.deploy.outputs.loaders }}"
          python3 data_loader_orchestrator.py --loaders "$LOADERS" --parallel 2

      - name: Upload deployment logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: deployment-logs
          path: logs/
          retention-days: 7

      - name: Report deployment status
        if: always()
        run: |
          if [[ "${{ job.status }}" == "success" ]]; then
            echo "✅ Deployment completed successfully"
            echo "Deployed loaders: ${{ steps.deploy.outputs.loaders }}"
          else
            echo "❌ Deployment failed"
            exit 1
          fi

  scheduled-execution:
    runs-on: ubuntu-latest
    # Only run if this is a scheduled trigger or manual dispatch
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install boto3 psycopg2-binary yfinance pandas numpy

      - name: Run critical data loaders
        run: |
          echo "Running critical data loaders on schedule..."
          python3 data_loader_orchestrator.py --priority critical --parallel 3

      - name: Run high priority loaders
        run: |
          echo "Running high priority data loaders..."
          python3 data_loader_orchestrator.py --priority high --parallel 2

  notify-completion:
    runs-on: ubuntu-latest
    needs: [deploy-loaders, scheduled-execution]
    if: always() && (needs.deploy-loaders.result != 'skipped' || needs.scheduled-execution.result != 'skipped')
    
    steps:
      - name: Send notification
        run: |
          STATUS="success"
          if [[ "${{ needs.deploy-loaders.result }}" == "failure" ]] || [[ "${{ needs.scheduled-execution.result }}" == "failure" ]]; then
            STATUS="failure"
          fi
          
          echo "Data loader deployment/execution completed with status: $STATUS"
          
          # Here you could add Slack/Discord/email notifications
          # Example:
          # curl -X POST -H 'Content-type: application/json' \
          #   --data "{\"text\":\"Data loader deployment $STATUS\"}" \
          #   ${{ secrets.SLACK_WEBHOOK_URL }}

# Schedule for automatic execution
# This workflow will also run on a schedule to ensure data freshness
on:
  schedule:
    # Run critical loaders every 4 hours during market hours (9 AM - 5 PM ET)
    - cron: '0 13,17,21 * * 1-5'  # 9 AM, 1 PM, 5 PM ET (UTC)
    # Run all loaders daily at 6 AM ET
    - cron: '0 10 * * 1-5'  # 6 AM ET (UTC)